-- ==========================================
-- Conversation Query Cache (Semantic Cache)
-- Stores embeddings + cleaned SQL queries +
-- results for fast semantic lookup
-- ==========================================

create table if not exists public.conversation_query_cache (
  id bigserial primary key,

  -- Session ID (ties cache entries to each user session)
  session_id text not null,

  -- Name of the table the SQL query was run on
  table_name text not null,

  -- Natural language question asked by the user
  question text not null,

  -- Normalized SQL query text generated by LLM
  normalized_sql text not null,

  -- JSON representation of SQL query results
  results jsonb,

  -- Embedding vector (1024 dims for mxbai-embed-large)
  embedding vector(1024),

  -- Timestamp for cache ordering
  created_at timestamptz not null default now()
);

-- ==========================================
-- Indexes for fast semantic search + lookup
-- ==========================================

-- HNSW vector index for cosine similarity search
create index if not exists conversation_query_cache_embedding_idx
on public.conversation_query_cache
using hnsw (embedding vector_cosine_ops);

-- Filter by session quickly
create index if not exists conversation_query_cache_session_idx
on public.conversation_query_cache (session_id);

-- Filter by table name
create index if not exists conversation_query_cache_table_idx
on public.conversation_query_cache (table_name);

-- Sort by newest cache entries
create index if not exists conversation_query_cache_created_idx
on public.conversation_query_cache (created_at desc);
